{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Assuming vocab_size is the size of the vocabulary\n# embedding_dim, hidden_dim, and output_dim are hyperparameters to be defined\n\nclass Seq2SeqBiLSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, output_dim):\n        super(Seq2SeqBiLSTM, self).__init__()\n\n        # Embedding layer\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n\n        # Encoder LSTM\n        self.encoder = nn.LSTM(embedding_dim, encoder_hidden_dim, batch_first=True)\n\n        # Decoder LSTM\n        self.decoder = nn.LSTM(embedding_dim, decoder_hidden_dim, batch_first=True)\n\n        # BiLSTM layer\n        self.bilstm = nn.LSTM(decoder_hidden_dim, decoder_hidden_dim, batch_first=True, bidirectional=True)\n\n        # Dense layer and Softmax for output\n        self.fc = nn.Linear(decoder_hidden_dim * 2, output_dim)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input_seq):\n        # Input to embedding layer\n        embedded = self.embedding(input_seq)\n\n        # Encoder LSTM\n        _, (hidden, cell) = self.encoder(embedded)\n\n        # Decoder LSTM with encoder's final hidden state as initial hidden state\n        decoder_output, _ = self.decoder(embedded, (hidden, cell))\n\n        # BiLSTM layer\n        bilstm_output, _ = self.bilstm(decoder_output)\n\n        # Dense layer and softmax\n        output = self.softmax(self.fc(bilstm_output))\n\n        return output\n\n# Example usage\nmodel = Seq2SeqBiLSTM(vocab_size=10000, embedding_dim=256, encoder_hidden_dim=128, decoder_hidden_dim=128, output_dim=10000)\ninput_seq = torch.randint(0, 10000, (1, 10)) # Example input sequence of length 10\noutput = model(input_seq)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:24:53.638122Z","iopub.execute_input":"2024-02-01T14:24:53.638571Z","iopub.status.idle":"2024-02-01T14:24:53.731498Z","shell.execute_reply.started":"2024-02-01T14:24:53.638540Z","shell.execute_reply":"2024-02-01T14:24:53.729771Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(output)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:25:45.275989Z","iopub.execute_input":"2024-02-01T14:25:45.276873Z","iopub.status.idle":"2024-02-01T14:25:45.324061Z","shell.execute_reply.started":"2024-02-01T14:25:45.276830Z","shell.execute_reply":"2024-02-01T14:25:45.323162Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"tensor([[[-2.2818, -2.3091, -2.3095,  ..., -2.3024, -2.3050, -2.3151],\n         [-2.2804, -2.2994, -2.3000,  ..., -2.2999, -2.3327, -2.2951],\n         [-2.2882, -2.3082, -2.3193,  ..., -2.2965, -2.3286, -2.2981],\n         ...,\n         [-2.3025, -2.3005, -2.2908,  ..., -2.3014, -2.2856, -2.2946],\n         [-2.3041, -2.3021, -2.2943,  ..., -2.3050, -2.3008, -2.3110],\n         [-2.2867, -2.3122, -2.2962,  ..., -2.3263, -2.2943, -2.3123]]],\n       grad_fn=<LogSoftmaxBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}